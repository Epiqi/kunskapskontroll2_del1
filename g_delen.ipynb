{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoretiska frågor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Lotta delar upp sin data i ”Träning”, ”Validering” och ”Test”, vad används respektive del för?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Svar: \n",
    "Träning: Används för att träna modellen, dvs. modellen lär sig från denna data, men det går inte att testa hur bra modellen  blivit på data som den redan känner till.\n",
    "Validering: Används för att finjustera hyperparametrar och utvärdera modellen under träning för att undvika överträning.\n",
    "Test: Data som inte finns med i träning eller valideringsdatan använder man för att slutligen utvärdera modellens prestanda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Förklara (gärna med ett exempel): Ordinal encoding, one-hot encoding, dummy variable encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Svar: \n",
    "Ordinal encoding:   Tilldelar varje kategori ett numeriskt värde baserat på en naturlig ordning.   \n",
    "Exempel: Liten (1), Medel (2), Stor (3)  \n",
    "\n",
    "One-hot encoding: Skapar en binär kolumn för varje kategori, där endast en kolumn har värdet 1 per observation.  \n",
    "Exempel:  \n",
    "Hund → [1, 0, 0]  \n",
    "Katt → [0, 1, 0]  \n",
    "Fågel → [0, 0, 1]  \n",
    "\n",
    "Dummy variable encoding: Liknar one-hot encoding men tar bort en kategori för att undvika multikollinearitet, dvs man vill få bort starka samband i de oberoende variablerna. Är de korrelerande kan det bli svårt för en modell att veta vilken variabel som påverkar mest.  \n",
    "Exempel: Om vi har tre kategorier (A, B, C), kodas de som:  \n",
    "A → [0, 0]  \n",
    "B → [1, 0]  \n",
    "C → [0, 1]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Göran påstår att datan antingen är ”ordinal” eller ”nominal”. Julia säger att detta måste tolkas. Hon ger ett exempel med att färger såsom {röd, grön, blå} generellt sett inte har någon inbördes ordning (nominal) men om du har en röd skjorta så är du vackrast på festen (ordinal) – vem har rätt?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Svar: \n",
    "Båda har väl rätt på sitt sätt: Datan är antingen nominal eller ordinal, men nominal data kan bli ordinal om man lägger till värdering till något som inte har det i vanliga fall.\n",
    "\n",
    "Nominal data har ingen inbördes ordning (ex. färger, djurarter, nationaliteter).\n",
    "Ordinal data har en logisk ordning (ex. betygsskala, klädstorlekar).\n",
    "\n",
    "Men tolkar man att man får högre rang av en röd skjorta, så har man infört en rangordning och färgen blir ordinal i det sammanhanget."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Vad används joblib och pickle till?\n",
    "\n",
    "## Svar:\n",
    "Det är två bibliotek som används för att lagra stora python-objekt.   \n",
    "Pickle verkar rekommenderas för något mindre objekt, medan joblib verkar bra på att hantera större objekt som NumPy-arrayer, ML-modeller och scikit-modeller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellera MNIST\n",
    "Använd maskininlärning för att modellera MNIST datan. Du skall utvärdera minst två olika modeller i ditt arbete och göra ett komplett ML-flöde, från början, där du laddar in data, till slut, där du utvärderar den bäst valda modellen på din test data. Hur du laddar ned MNIST datan kan du se här."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Jag har valt att testa tre olika modeller som jag tror kommer fungera ganska bra med tanke på vad vi lärt oss i kursen och som även ingått i kursen, (samt att jag haft lite dåligt med tid sista två veckorna så för min egen skull vill jag också testa fler):  \n",
    "Support Vector Machine (SVM) och Random Forest (RF) och Extra Tree (ET) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Först har jag installerat joblib).  \n",
    "Börja med alla importer och installationer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jag laddar ner MNIST-datasetet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, cache=True, as_frame=False)\n",
    "X = mnist[\"data\"][:70000]\n",
    "y = mnist[\"target\"].astype(np.uint8)[:70000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Från datasetets beskrivning vet vi att vi kan använda de första 70.000 värdena för att träna på machinelearning, då de bearbetat den datan för att vara bra träningsdata. Så jag delar in den i träning, test och valideringsdata. 50000 i test och 10000 i test och validering respektive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=50000, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=10000, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skala data för SVM (ET och RF behöver inte skalning):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jag använder gridsearch för att optimera hyperparametrar och för att slippa repetativ kod så skapar jag en funktion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimaze_train_and_evaluate_model(model, param_grid, X_train, y_train, X_val, y_val, scaled=False):\n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train_scaled if scaled else X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    accuracy = accuracy_score(y_val, best_model.predict(X_val_scaled if scaled else X_val))\n",
    "    return best_model, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Välj hyperparametrar och skicka in i vår funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_trees_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "extra_trees, et_acc = optimaze_train_and_evaluate_model(ExtraTreesClassifier(random_state=42), extra_trees_params, X_train, y_train, X_val, y_val)\n",
    "\n",
    "random_forest_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}\n",
    "random_forest, rf_acc = optimaze_train_and_evaluate_model(RandomForestClassifier(random_state=42), random_forest_params, X_train, y_train, X_val, y_val)\n",
    "\n",
    "svm_params = {'C': [1, 10, 100], 'gamma': ['scale', 'auto']}\n",
    "svm, svm_acc = optimaze_train_and_evaluate_model(SVC(kernel='rbf'), svm_params, X_train_scaled, y_train, X_val_scaled, y_val, scaled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jag väljer bäst modell enligt valideringsdata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bästa modellen baserat på valideringsdata: SVM med accuracy: 0.9712\n"
     ]
    }
   ],
   "source": [
    "model_scores = {\n",
    "    \"Extra Trees\": et_acc,\n",
    "    \"Random Forest\": rf_acc,\n",
    "    \"SVM\": svm_acc\n",
    "}\n",
    "\n",
    "best_model_name = max(model_scores, key=model_scores.get)\n",
    "best_model = {\"Extra Trees\": extra_trees, \"Random Forest\": random_forest, \"SVM\": svm}[best_model_name]\n",
    "print(f\"Bästa modellen baserat på valideringsdata: {best_model_name} med accuracy: {model_scores[best_model_name]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sen evaluerar jag den bästa modellen med testdatan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bästa modellens test-accuracy: 0.968\n"
     ]
    }
   ],
   "source": [
    "best_test_acc = accuracy_score(y_test, best_model.predict(X_test if best_model_name != \"SVM\" else X_test_scaled))\n",
    "print(f\"Bästa modellens test-accuracy: {best_test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sen sparar jag ner den bästa modellen i förhoppning om att jag hinner gör VG-delen, för den verkar väldigt rolig!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best_mnist_model.joblib']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(best_model, \"best_mnist_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
